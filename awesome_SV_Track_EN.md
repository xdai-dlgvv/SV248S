# Awesome Satellite Video Tracking

This document is mainly to sort out the relevant content of satellite video and satellite video tracking, so as to facilitate the subsequent researchers to get started faster.
This documentation plan involves the following tasks:
1. Single object tracking
2. Multiple object tracking
3. Moving object detection

Due to the particularity of the remote sensing field, most papers do not open source their codes. The first part of this document mainly organizes the open source codes, and marks part of the codes for testing according to the situation, so as to facilitate the reference of subsequent researchers.

Since our test marks are also time-sensitive and random (for example, our environment is different from the author's performance difference, the author has updated the link to provide the complete test code, etc.), so this work is only an attempt to fully reflect the results of our test. If this doesn't match your results, feel free to contact us to discuss these. After all, the test results of satellite video data are likely to have a particularly large relationship with the parameters. This needs to be judged by yourself.



## Open Source Code

<!-- 模板：

1. **方法简写**: 论文全称 [[Paper]]() [[Code]]() 
发表刊物：刊名，年份 -->

### SOT

1. **CFME**: Object Tracking in Satellite Videos by Improved Correlation Filters With Motion Estimations  
  [[Paper]](https://ieeexplore.ieee.org/abstract/document/8880656) [[Code]](https://github.com/SY-Xuan/CFME)  
  **Publications**：IEEE Transactions on Geoscience and Remote Sensing, 2020  
  <!-- **Abstract**: As a new method of Earth observation, video satellite is capable of monitoring specific events on the Earth's surface continuously by providing high-temporal resolution remote sensing images. The video observations enable a variety of new satellite applications such as object tracking and road traffic monitoring. In this article, we address the problem of fast object tracking in satellite videos, by developing a novel tracking algorithm based on correlation filters embedded with motion estimations. Based on the kernelized correlation filter (KCF), the proposed algorithm provides the following improvements: 1) proposing a novel motion estimation (ME) algorithm by combining the Kalman filter and motion trajectory averaging and mitigating the boundary effects of KCF by using this ME algorithm and 2) solving the problem of tracking failure when a moving object is partially or completely occluded. The experimental results demonstrate that our algorithm can track the moving object in satellite videos with 95% accuracy. -->

2. **CoCRF-TrackNet**: A Collaborative Learning Tracking Network for Remote Sensing Videos  
[[Paper]](https://ieeexplore.ieee.org/abstract/document/9819825) [[Code]](https://github.com/Dawn5786/CoCRF-TrackNet)  
**Publications**：IEEE Transactions on Cybernetics, 2022
unpublished weights.  
<!-- **Abstract**: With the increasing accessibility of remote sensing videos, remote sensing tracking is gradually becoming a hot issue. However, accurately detecting and tracking in complex remote sensing scenes is still a challenge. In this article, we propose a collaborative learning tracking network for remote sensing videos, including a consistent receptive field parallel fusion module (CRFPF), dual-branch spatial-channel co-attention (DSCA) module, and geometric constraint retrack strategy (GCRT). Considering the small-size objects of remote sensing scenes are difficult for general forward networks to extract effective features, we propose a CRFPF-module to establish parallel branches with consistent receptive fields to separately extract from shallow to deep features and then fuse hierarchical features adaptively. Since the objects and their background are difficult to distinguish, the proposed DSCA-module uses the spatial-channel co-attention mechanism to collaboratively learn the relevant information, which enhances the saliency of the objects and regresses to precise bounding boxes. Considering the interference of similar objects, we designed a GCRT-strategy to judge whether there is a false detection through the estimated motion trajectory and then recover the correct object by weakening the feature response of interference. The experimental results and theoretical analysis on multiple datasets demonstrate our proposed method’s feasibility and effectiveness. Code and net are available at https://github.com/Dawn5786/CoCRF-TrackNet . -->

3. **ThickSiam**: High-resolution Satellite Video Object Tracking Based on ThickSiam Framework  
[[Paper]](https://www.tandfonline.com/doi/full/10.1080/15481603.2022.2163063) [[Code]](https://github.com/CVEO/ThickSiam)  
**Publications**：GIScience \& Remote Sensing, 2023  
*The data set used in the paper is provided, but the test code is not provided.*  
<!-- **Abstract**: High-resolution satellite videos realize the short-dated gaze observation of the designated area on the ground, and its emergence has improved the temporal resolution of remote sensing data to the second level. Single object tracking (SOT) task in satellite video has attracted considerable attention. However, it faces challenges such as complex background, poor object feature representation, and lack of publicly available datasets. To cope with these challenges, a ThickSiam framework consisting of a Thickened Residual Block Siamese Network (TRBS-Net) for extracting robust semantic features to obtain the initial tracking results and a Remoulded Kalman Filter (RKF) module for simultaneously correcting the trajectory and size of the targets is designed in this work. The results of TRBS-Net and RKF modules are combined by an N-frame-convergence mechanism to achieve accurate tracking results. Ablation experiments are implemented on our annotated dataset to evaluate the performance of the proposed ThickSiam framework and other 19 state-of-the-art trackers. The comparison results show that our ThickSiam tracker obtains a precision value of 0.991 and a success value of 0.755 while running at 56.849 FPS implemented on one NVIDIA GTX1070Ti GPU. -->

4. **MACF**：  
[[Paper]]() No paper [[Code]](https://github.com/binlin-cv/MACF)  
发表刊物：  
获得了ICPR 2022运动目标检测和单目标检测。代码未上传。


### MOT

1. Adaptive Birth for the GLMB Filter for object tracking in satellite videos  
[[Paper]](https://ieeexplore.ieee.org/abstract/document/9943411/) [[Code]](https://github.com/binlin-cv/MACF)  
**Publications**：2022 IEEE 32st International Workshop on Machine Learning for Signal Processing (MLSP)  
<!-- **Abstract**: The Generalized Labeled Multi-Bernoulli (GLMB) filter attains remarkable results in Multi-Object Tracking (MOT). Nevertheless, the GLMB filter relies on strong assumptions such as prior knowledge of targets' initial state. Pragmatic scenarios such as satellite video object tracking challenge these assumptions as objects appear at random locations and object detectors output numerous false positives. We present an enhanced version of the GLMB filter that learns from previous trajectories to estimate accurate hypotheses initializations. We keep track of previous target states and use this information to sample the initial velocities of new-born targets. This addition significantly improves the performance of the GLMB in videos with low Frames Per Second (FPS), where the target's initial states are paramount for object tracking. We test this enhanced GLMB filter versus comparable trackers and previous solutions for the GLMB filter and show that our filter obtains better performance. Code is available at https://github.com/Ayana-Inria/GLMB-adaptive-birth-satellite-videos. -->

2. **TGraM**: Multi-Object Tracking in Satellite Videos with Graph-Based Multi-Task Modeling  
[[Paper]](https://ieeexplore.ieee.org/abstract/document/9715124) [[Code]](https://github.com/zuzi2015/TGraM)  
**Publications**：IEEE Transactions on Geoscience and Remote Sensing， 2022  
<!-- **Abstract**: Recently, satellite video has become an emerging means of earth observation, providing the possibility of tracking moving objects. However, the existing multi-object trackers are commonly designed for natural scenes without considering the characteristics of remotely sensed data. In addition, most trackers are composed of two independent stages of detection and reidentification (ReID), which means that they cannot be mutually promoted. To this end, we propose an end-to-end online framework, which is called TGraM, for multi-object tracking in satellite videos. It models multi-object tracking as a graph information reasoning procedure from the multitask learning perspective. Specifically, a graph-based spatiotemporal reasoning module is presented to mine the potential high-order correlations between video frames. Furthermore, considering the inconsistency of optimization objectives between detection and ReID, a multitask gradient adversarial learning strategy is designed to regularize each task-specific network. In addition, aiming at the data scarcity in this field, a large-scale and high-resolution Jilin-1 satellite video dataset for multi-object tracking (AIR-MOT) is built for the experiments. Compared with state-of-the-art multi-object trackers, TGraM achieves efficient collaborative learning between detection and ReID, improving the tracking accuracy by 1.2 multiple object tracking accuracy. The code and dataset will be available online ( https://github.com/HeQibin/TGraM ). -->

### Datasets
1. **SV248S**: Deep Learning-Based Object Tracking in Satellite Videos: A Comprehensive Survey With a New Dataset  
[[paper]](https://ieeexplore.ieee.org/document/9875020) [[code]](https://github.com/xdai-dlgvv/sv_dataset)  
**Publications**：IEEE Geoscience and Remote Sensing Magazine，2022  
<!-- **Abstract**: As a fundamental task for research in satellite videos (SVs), object tracking is used to track the target of interest in traffic evaluation, military security, and so forth. The current satellite technology in the remote sensing field makes it possible to track moving targets with a relatively high frame rate and image resolution. However, objects under this special view are often small and blurry, making it hard to extract deep features effectively. As a result, quite a few deep learning (DL) methods were proposed for object tracking in SVs. In addition, evaluation criteria for daily life videos (DLVs) are not fully applicable to SVs, which always get low precision evaluation results for tiny objects. In this article, we make three contributions to the research on SVs. First, a new single object tracking (SOT) dataset, named SV248S , is proposed, including 248 sequences with high-precision manual annotation, and 10 kinds of attribute tags are designed to completely represent the difficulties during tracking. Second, two high-precision evaluation methods are proposed, especially for small object tracking. Finally, 28 DL-based state-of-the-art (SOTA) tracking methods, from 2017 to 2021, covering popular frameworks, are evaluated and compared on the proposed dataset. Furthermore, some guidelines for effectively adopting DL-based methods are summarized based on comprehensive experimental results. -->

2. **VISO**: Detecting and Tracking Small and Dense Moving Objects in Satellite Videos: A Benchmark  
[[Paper]](https://ieeexplore.ieee.org/abstract/document/9625976) [[Code]](https://github.com/QingyongHu/VISO)  
**Publications**：IEEE Transactions on Geoscience and Remote Sensing， 2021  
<!-- **Abstract**: Satellite video cameras can provide continuous observation for a large-scale area, which is important for many remote sensing applications. However, achieving moving object detection and tracking in satellite videos remains challenging due to the insufficient appearance information of objects and lack of high-quality datasets. In this article, we first build a large-scale satellite video dataset with rich annotations for the task of moving object detection and tracking. This dataset is collected by the Jilin-1 satellite constellation and composed of 47 high-quality videos with 1 646 038 instances of interest for object detection and 3711 trajectories for object tracking. We then introduce a motion modeling baseline to improve the detection rate and reduce false alarms based on accumulative multiframe differencing and robust matrix completion. Finally, we establish the first public benchmark for moving object detection and tracking in satellite videos and extensively evaluate the performance of several representative approaches on our dataset. Comprehensive experimental analyses and insightful conclusions are also provided. The dataset is available at https://github.com/QingyongHu/VISO . -->

3. **ThickSiam**: High-resolution Satellite Video Object Tracking Based on ThickSiam Framework  
[[Paper]](https://www.tandfonline.com/doi/full/10.1080/15481603.2022.2163063) [[Code]](https://github.com/CVEO/ThickSiam)  
**Publications**：GIScience \& Remote Sensing, 2023  
<!-- **Abstract**: High-resolution satellite videos realize the short-dated gaze observation of the designated area on the ground, and its emergence has improved the temporal resolution of remote sensing data to the second level. Single object tracking (SOT) task in satellite video has attracted considerable attention. However, it faces challenges such as complex background, poor object feature representation, and lack of publicly available datasets. To cope with these challenges, a ThickSiam framework consisting of a Thickened Residual Block Siamese Network (TRBS-Net) for extracting robust semantic features to obtain the initial tracking results and a Remoulded Kalman Filter (RKF) module for simultaneously correcting the trajectory and size of the targets is designed in this work. The results of TRBS-Net and RKF modules are combined by an N-frame-convergence mechanism to achieve accurate tracking results. Ablation experiments are implemented on our annotated dataset to evaluate the performance of the proposed ThickSiam framework and other 19 state-of-the-art trackers. The comparison results show that our ThickSiam tracker obtains a precision value of 0.991 and a success value of 0.755 while running at 56.849 FPS implemented on one NVIDIA GTX1070Ti GPU. -->

4. **TGraM**: Multi-Object Tracking in Satellite Videos with Graph-Based Multi-Task Modeling  
[[Paper]](https://ieeexplore.ieee.org/abstract/document/9715124) [[Code]](https://github.com/zuzi2015/TGraM)  
**Publications**：IEEE Transactions on Geoscience and Remote Sensing， 2022  
<!-- **Abstract**: Recently, satellite video has become an emerging means of earth observation, providing the possibility of tracking moving objects. However, the existing multi-object trackers are commonly designed for natural scenes without considering the characteristics of remotely sensed data. In addition, most trackers are composed of two independent stages of detection and reidentification (ReID), which means that they cannot be mutually promoted. To this end, we propose an end-to-end online framework, which is called TGraM, for multi-object tracking in satellite videos. It models multi-object tracking as a graph information reasoning procedure from the multitask learning perspective. Specifically, a graph-based spatiotemporal reasoning module is presented to mine the potential high-order correlations between video frames. Furthermore, considering the inconsistency of optimization objectives between detection and ReID, a multitask gradient adversarial learning strategy is designed to regularize each task-specific network. In addition, aiming at the data scarcity in this field, a large-scale and high-resolution Jilin-1 satellite video dataset for multi-object tracking (AIR-MOT) is built for the experiments. Compared with state-of-the-art multi-object trackers, TGraM achieves efficient collaborative learning between detection and ReID, improving the tracking accuracy by 1.2 multiple object tracking accuracy. The code and dataset will be available online ( https://github.com/HeQibin/TGraM ). -->

5. **SatSOT**: A Benchmark Dataset for Satellite Video Single Object Tracking  
  [[Paper]](https://ieeexplore.ieee.org/document/9672083) [[Code]]() No code  
  **Publications**: IEEE Transactions on Geoscience and Remote Sensing, 2022  
  <!-- **Abstract**: By imaging a specific area continuously, satellite video shows excellent capability in various applications such as surveillance and traffic management. Although object tracking has made significant progress in recent years, development in satellite object tracking is limited by the lack of open-source satellite datasets. It is thus essential to establish a satellite video object-tracking benchmark to fill the gap and advance the research. In this work, we present SatSOT, the first densely annotated satellite video single object-tracking benchmark dataset. SatSOT consists of 105 sequences with 27664 frames, 11 attributes, and four categories of typical moving targets in satellite videos: car, plane, ship, and train. Based on the proposed dataset and the significant challenges in satellite video object tracking, such as small targets, background interference, and severe occlusion, detailed evaluation and analysis are performed on 15 among the best and most representative tracking algorithms, which provides a basis for further research on satellite video object tracking. -->

## Related Paper
### SOT

1. A Quantum Evolutionary Learning Tracker for Video  
  [[Paper]](https://ieeexplore.ieee.org/abstract/document/10092876)  No code  
  **Publications**: IEEE Transactions on Evolutionary Computation , 2023   
  **Abstract**: Video object tracking has been a popular area in the field of computer vision. As video data evolves, more special perspectives and challenging video data are constantly kept up to date. This poses challenges for object tracking tasks and places higher demands on the generalization capabilities of the models. In this paper, we propose a novel quantum evolutionary learning tracker for video. The model combines quantum evolution with deep networks for tracking video objects. The model uses a quantum evolutionary learning tracker to generate a reliable population of candidate regions and a deep network for classification. In particular, the quantum evolutionary predictor predicts the object motion state through rotation operator and trajectory inference, and provides motion state information for the tracker. The predictor can incorporate object history contextual information and can provide stable candidate estimation populations for the model in case of failure of appearance features. Both quantum evolution and deep networks are combined to form an end-to-end online video object tracker. In addition, we propose a new video object tracking evaluation algorithm, Balanced Intersection over Union. The evaluation algorithm uses aspect ratios to balance the share of overlap and distance. Finally, we test the model on the OTB 2015 dataset for natural video and on the SV248A10-SOT dataset for satellite video. The performance of the proposed model is also analyzed and validated by comparing it with more than twenty classical tracker models. The experimental results show that our model has high generalization ability and robustness.
  
2. **SiamMDM**: An Adaptive Fusion Network With Dynamic Template for Real-Time Satellite Video Single Object Tracking  
  [[Paper]](https://ieeexplore.ieee.org/abstract/document/10113336)  No code  
  **Publications**: IEEE Transactions on Geoscience and Remote Sensing, 2023  
  **Abstract**: Tracking moving targets in satellite videos has attracted wide attention recently. However, the development of target tracking in satellite videos is much slower than that in general videos for the following key reasons. First, typical moving objects in satellite videos consist of few pixels and lose most of their appearance features, making it difficult for the tracker to distinguish the target from the background. Second, the appearance of satellite video objects often changes due to occlusion, illumination variation, or other factors. Classic Siamese tracking networks only use the first frame as the target template, leading to poor tracking results. Third, when the target is fully occluded, it is difficult for the tracker to recapture the target. To address the above problems, we propose a Siamese tracking network based on multiple (M) response map fusion and spatiotemporal constraints in this article. By generating response maps at different layers of the tracking network and fusing them adaptively, small objects in the satellite videos can be tracked more accurately. Furthermore, a dynamic (D) template update strategy is proposed to cope with possible changes in the appearance of objects in satellite videos, preventing the high dependence on the initial frame. To recapture the target, a score-guided target motion (M) trajectory prediction model is proposed. We call the proposed Siamese tracking network SiamMDM for short. We conducted complete experiments on SatSOT and SV248S, two large satellite video target tracking datasets. The results show that our method achieves state-of-the-art tracking performance while running at over 110 frames/s (FPS).

3. Object Tracking Based on Satellite Videos: A Literature Review  
  [[Paper]](https://www.mdpi.com/2072-4292/14/15/3674)  No code  
  **Publications**: Remote Sens, 2022  
  **Abstract**: Video satellites have recently become an attractive method of Earth observation, providing consecutive images of the Earth’s surface for continuous monitoring of specific events. The development of on-board optical and communication systems has enabled the various applications of satellite image sequences. However, satellite video-based target tracking is a challenging research topic in remote sensing due to its relatively low spatial and temporal resolution. Thus, this survey systematically investigates current satellite video-based tracking approaches and benchmark datasets, focusing on five typical tracking applications: traffic target tracking, ship tracking, typhoon tracking, fire tracking, and ice motion tracking. The essential aspects of each tracking target are summarized, such as the tracking architecture, the fundamental characteristics, primary motivations, and contributions. Furthermore, popular visual tracking benchmarks and their respective properties are discussed. Finally, a revised multi-level dataset based on WPAFB videos is generated and quantitatively evaluated for future development in the satellite video-based tracking area. In addition, 54.3% of the tracklets with lower Difficulty Score (DS) are selected and renamed as the Easy group, while 27.2% and 18.5% of the tracklets are grouped into the Medium-DS group and the Hard-DS group, respectively.
  
4. Object Tracking in Satellite Videos Based on Improved Kernel Correlation Filter Assisted by Road Information  
  [[Paper]](https://www.mdpi.com/2072-4292/14/17/4215)  No code  
  **Publications**: Remote Sens, 2022  
  **Abstract**: Video satellites can stare at target areas on the Earth’s surface to obtain high-temporal-resolution remote sensing videos, which make it possible to track objects in satellite videos. However, it should be noted that the object size in satellite videos is usually small and has less textural property, and the moving objects in satellite videos are easily occluded, which puts forward higher requirements for the tracker. In order to solve the above problems, consider that the remote sensing image contains rich road information, which can be used to constrain the trajectory of the object in a satellite video, this paper proposes an improved Kernel Correlation Filter (KCF) assisted by road information to track small objects, especially when the object is occluded. Specifically, the contributions of this paper are as follows: First, the tracking confidence module is reconstructed, which integrates the peak response and the average peak correlation energy of the response map to more accurately judge whether the object is occluded. Then, an adaptive Kalman filter is designed to adaptively adjust the parameters of the Kalman filter according to the motion state of the object, which improves the robustness of tracking and reduces the tracking drift after the object is occluded. Last but not least, an object tracking strategy assisted by road information is recommended, which searches for objects with road information as constraints, to locate objects more accurately. After the above improvements, compared with the KCF tracker, our method improves the tracking precision by 35.9% and the tracking success rate by 18.1% with the tracking rate at a speed of 300 frames per second, which meets the real-time requirements.
  
5. Vehicle Tracking on Satellite Video Based on Historical Model  
  [[Paper]](https://ieeexplore.ieee.org/abstract/document/9847077)  No code  
  **Publications**: IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 2022  
  **Abstract**: Vehicle tracking on satellite videos poses a challenge for the existing object tracking algorithms due to the few features, object occlusion, and similar objects appearance. To improve the performance of the object tracking algorithm, a historical-model-based tracker intended for satellite videos is proposed in this study. It updates the tracker by using the historical model of each frame in the video, which contains plenty of object information and background information, so as to improve tracking ability on few-feature objects. Furthermore, a historical model evaluation scheme is designed to obtain reliable historical models, which ensures that the tracker is sensitive to the object in the current frame, thus avoiding the impact caused by changes in object appearance and background. Besides, to solve the drift issue of the tracker caused by object occlusion and the appearance of similar objects, an antidrift tracker correction scheme is proposed as well. According to the comparative experiments conducted on satellite videos dataset SatSOT, our tracker produces an excellent performance. Moreover, sensitivity analysis, varying criteria comparative experiments, and ablation experiments are conducted to demonstrate that the proposed schemes are effective in improving the precision and success rate of the tracker.
  
6. Object Tracking in Satellite Videos: A Spatial-Temporal Regularized Correlation Filter Tracking Method With Interacting Multiple Model  
  [[Paper]](https://ieeexplore.ieee.org/abstract/document/9786761)  No code  
  **Publications**: IEEE Geoscience and Remote Sensing Letters, 2022  
  **Abstract**: Target occlusion is common in satellite videos, which makes object tracking difficult because most state-of-the-art trackers are not robust to occlusion, particularly complete occlusion. In this letter, we propose a novel correlation filter algorithm with an interacting multiple model (IMM) for object tracking in satellite videos that combines the strength of the correlation filter and the IMM. When the target is occluded, we utilize the IMM to predict target position. Therefore, the proposed tracker is robust to occlusion. The experimental results demonstrate that our tracker performs favorably when the target is occluded and achieves excellent performance compared with state-of-the-art methods.
  
7. Object Tracking in Satellite Videos: Correlation Particle Filter Tracking Method With Motion Estimation by Kalman Filter  
  [[Paper]](https://ieeexplore.ieee.org/abstract/document/9875357)  No code  
  **Publications**: IEEE Transactions on Geoscience and Remote Sensing, 2022  
  **Abstract**: Object tracking in satellite videos faces various challenges such as target occlusion, target rotation, and background clutter. This study proposes a Correlation particle filter (CPF) algorithm with motion estimation (ME) for object tracking in satellite videos. The tracker, called correlation particle Kalman filter (CPKF), combines the strengths of the correlation, particle, and Kalman filters. Compared with the existing tracking methods based on correlation filters, the proposed tracker has three major advantages: 1) particle sampling, and ME build robustness against partial and complete occlusion; 2) color histogram model makes it robust to target rotation; and 3) fusion of multiple feature response maps effectively handles background clutter and low contrast. The experimental results demonstrate that the proposed tracking algorithm performs better than the state-of-the-art methods.
  
8. Object Tracking in Satellite Videos Based on Siamese Network With Multidimensional Information-Aware and Temporal Motion Compensation  
  [[Paper]](https://ieeexplore.ieee.org/abstract/document/9908539)  No code  
  **Publications**: IEEE Geoscience and Remote Sensing Letters, 2022  
  **Abstract**: The availability of many commercial satellites has created favorable conditions for tracking typical objects in remote sensing sequences, making them useful in numerous applications. However, small objects, multiple similar disruptors, background clutter, and occlusion are significant challenges encountered in this field. This study proposes the novel tracker-temporal motion compensation Siamese network (Siam-TMC) for remote sensing tracking. Our method relies on a multidimensional information-aware (Dim-Aware) module and a temporal motion compensation (TMComp) mechanism. Notably, we propose a dual branch-based Dim-Aware module that brings together foreground and high-frequency information to distinguish between critical small objects and interferers. In addition, a TMComp mechanism using temporal motion information was designed to mitigate object trajectory drift through the supervision of occlusion detection. Detailed experimental comparisons on a benchmark dataset show that our method outperforms the state-of-the-art tracking models, particularly in occlusion scenarios.

9. **HRSiam**: High-Resolution Siamese Network, Towards Space-Borne Satellite Video Tracking  
  [[Paper]](https://ieeexplore.ieee.org/document/9350236)  No code  
  **Publications**: IEEE Transactions on Image Processing, 2021  
  **Abstract**: Tracking moving objects from space-borne satellite videos is a new and challenging task. The main difficulty stems from the extremely small size of the target of interest. First, because the target usually occupies only a few pixels, it is hard to obtain discriminative appearance features. Second, the small object can easily suffer from occlusion and illumination variation, making the features of objects less distinguishable from features in surrounding regions. Current state-of-the-art tracking approaches mainly consider high-level deep features of a single frame with low spatial resolution, and hardly benefit from inter-frame motion information inherent in videos. Thus, they fail to accurately locate such small objects and handle challenging scenarios in satellite videos. In this article, we successfully design a lightweight parallel network with a high spatial resolution to locate the small objects in satellite videos. This architecture guarantees real-time and precise localization when applied to the Siamese Trackers. Moreover, a pixel-level refining model based on online moving object detection and adaptive fusion is proposed to enhance the tracking robustness in satellite videos. It models the video sequence in time to detect the moving targets in pixels and has ability to take full advantage of tracking and detecting. We conduct quantitative experiments on real satellite video datasets, and the results show the proposed HIGH-RESOLUTION SIAMESE NETWORK (HRSiam) achieves state-of-the-art tracking performance while running at over 30 FPS.
  
10.  **MBLT**: Learning Motion and Background for Vehicle Tracking in Satellite Videos  
  [[Paper]](https://ieeexplore.ieee.org/abstract/document/9533178)  No code  
  **Publications**: IEEE Transactions on Geoscience and Remote Sensing, 2021  
  **Abstract**: Recently, satellite videos provide a new way to dynamically monitor the Earth’s surface. The interpretation of satellite videos has attracted more and more attentions. In this article, we focus on the problem of the vehicle tracking in satellite videos. Satellite videos usually own a lower resolution, which leads to the following phenomena: 1) the size of a vehicle target usually includes a few pixels and 2) vehicles are usually with similar appearance which easily results in the wrong tracking within the observing region. General popular tracking methods usually focus on the representation of the target and recognize it from background which are limited in this problem. As a consequence, in this article, we propose to learn motion and background of the target in order to help the trackers recognize the target with higher accuracy. A prediction network is proposed to predict the location probability of the target in each pixel in next frame based on fully convolutional network (FCN) which is learned from previous results. In addition, a segmentation method is introduced to generate the feasible region for target in each frame and assign high probability for such a region. For quantitative comparison, we manually annotate 20 representative vehicle targets from nine satellite videos taken by JiLin-1. In addition, we also selected two public satellite video datasets for experiments. Numerous experimental results demonstrate the superior of the proposed method.
  
11.  Remote Sensing Object Tracking With Deep Reinforcement Learning Under Occlusion  
  [[Paper]](https://ieeexplore.ieee.org/document/9492311)  No code  
  **Publications**: IEEE Transactions on Geoscience and Remote Sensing , 2021  
  **Abstract**: Object tracking is an important research direction of space Earth observation in the field of remote sensing. Although the existing correlation filter-based and deep learning (DL)-based object tracking algorithms have achieved great success, they are still unsatisfactory for the problem of object occlusion. The occlusion caused by the complex change in background, and the deviation of the tracking lens, causes object information to go missing, which leads to the omission of detection. Traditionally, most methods for object tracking under occlusion adopt a complex network model, which redetects the occluded object. To address this issue, we propose a novel object tracking approach. First, an action decision-occlusion handling network (AD-OHNet) based on deep reinforcement learning (DRL) is built to achieve low computational complexity for object tracking under occlusion. Second, the temporal and spatial context, the object appearance model, and the motion vector are adopted to provide the occlusion information, which drives actions in reinforcement learning under complete occlusion and contributes to improving the accuracy of tracking while maintaining speed. Finally, the proposed AD-OHNet is evaluated on three remote sensing video datasets of Bogota, Hong Kong, and San Diego taken from Jilin-1 commercial remote sensing satellites. The video datasets all shared problems of low spatial resolution, background clutter, and small objects. Experimental results on the three video datasets validate the effectiveness and efficiency of the proposed tracker.
  
12.  Single Object Tracking in Satellite Videos: Deep Siamese Network Incorporating an Interframe Difference Centroid Inertia Motion Model  
  [[Paper]](https://www.mdpi.com/2072-4292/13/7/1298)  No code  
  **Publications**: Remote Sens, 2021  
  **Abstract**: Satellite video single object tracking has attracted wide attention. The development of remote sensing platforms for earth observation technologies makes it increasingly convenient to acquire high-resolution satellite videos, which greatly accelerates ground target tracking. However, overlarge images with small object size, high similarity among multiple moving targets, and poor distinguishability between the objects and the background make this task most challenging. To solve these problems, a deep Siamese network (DSN) incorporating an interframe difference centroid inertia motion (ID-CIM) model is proposed in this paper. In object tracking tasks, the DSN inherently includes a template branch and a search branch; it extracts the features from these two branches and employs a Siamese region proposal network to obtain the position of the target in the search branch. The ID-CIM mechanism was proposed to alleviate model drift. These two modules build the ID-DSN framework and mutually reinforce the final tracking results. In addition, we also adopted existing object detection datasets for remotely sensed images to generate training datasets suitable for satellite video single object tracking. Ablation experiments were performed on six high-resolution satellite videos acquired from the International Space Station and “Jilin-1” satellites. We compared the proposed ID-DSN results with other 11 state-of-the-art trackers, including different networks and backbones. The comparison results show that our ID-DSN obtained a precision criterion of 0.927 and a success criterion of 0.694 with a frames per second (FPS) value of 32.117 implemented on a single NVIDIA GTX1070Ti GPU.
  
13.  Rotation adaptive correlation filter for moving object tracking in satellite videos  
  [[Paper]](https://www.sciencedirect.com/science/article/pii/S0925231221000862)  No code  
  **Publications**: Neurocomputing, 2021  
  **Abstract**: As a new method of Earth observation, video satellite can provide high-temporal resolution remote sensing images for object tracking. Object tracking in satellite videos is promising yet challenging in computer vision. Although many algorithms for satellite video object tracking have been proposed, none of them solve the problem of tracking rotating object. Due to the nadir view, the rotation of an object is very common in the satellite videos. This problem urgently needs to be addressed. In this paper, a rotation-adaptive correlation filter (RACF) tracking algorithm is proposed to address the problem caused by the rotation of object. The proposed algorithm provides the following improvements: (a) A method of estimating the object rotation angle to keep the feature map stable during the object rotation is proposed. This method can overcome the drawback of histogram of oriented gradient (HOG) based trackers, which cannot deal with the rotation of objects in satellite videos; and (b) making the algorithm capable of estimating the change in the bounding box size caused by object’s rotation. The experimental results demonstrate that our algorithm can track object with a 99.84% precision score and 92.96% success score in six videos from the Jilin-1 satellite constellation.
  
14.  Remote sensing target tracking in satellite videos based on a variable-angle-adaptive Siamese network  
  [[Paper]](https://ietresearch.onlinelibrary.wiley.com/doi/full/10.1049/ipr2.12170)  No code  
  **Publications**: IET Image Processing, 2021  
  **Abstract**: Remote sensing target tracking in satellite videos plays a key role in various fields. However, due to the complex backgrounds of satellite video sequences and many rotation changes of highly dynamic targets, typical target tracking methods for natural scenes cannot be used directly for such tasks, and their robustness and accuracy are difficult to guarantee. To address these problems, an algorithm is proposed for remote sensing target tracking in satellite videos based on a variable-angle-adaptive Siamese network (VAASN). Specifically, the method is based on the fully convolutional Siamese network (Siamese-FC). First, for the feature extraction stage, to reduce the impact of complex backgrounds, we present a new multifrequency feature representation method and introduce the octave convolution (OctConv) into the AlexNet architecture to adapt to the new feature representation. Then, for the tracking stage, to adapt to changes in target rotation, a variable-angle-adaptive module that uses a fast text detector with a single deep neural network (TextBoxes++) is introduced to extract angle information from the template frame and detection frames and performs angle consistency update operations on the detection frames. Finally, qualitative and quantitative experiments using satellite datasets show that the proposed method can improve tracking accuracy while achieving high efficiency.
  
15.  Object Tracking in Satellite Videos Based on Convolutional Regression Network With Appearance and Motion Features  
  [[Paper]](https://ieeexplore.ieee.org/document/8994098)  No code  
  **Publications**: IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 2020  
  **Abstract**: Object tracking is one of the most important components in numerous applications of computer vision. Remote sensing videos provided by commercial satellites make it possible to extend this topic into the earth observation domain. In satellite videos, typical moving targets like vehicles and planes only cover a small area of pixels, and they could easily be confused with surrounding complex ground scenes. Similar objects nearby in satellite videos can hardly be differed by appearance details due to the resolution constraint. Thus, tracking drift caused by distractions is also a thorny problem. Facing challenges, traditional tracking methods such as correlation filters with hand-crafted visual features achieve unsatisfactory results in satellite videos. Methods based on deep neural networks have demonstrated their superiority in various ordinary visual tracking benchmarks, but their results on satellite videos remain unexplored. In this article, deep learning technologies are applied to object tracking in satellite videos for better performance. A simple regression network is used to combine a regression model with convolutional layers and a gradient descent algorithm. The regression network fully exploits the abundant background context to learn a robust tracker. Instead of handcrafted features, both appearance features and motion features, which are extracted by pretrained deep neural networks, are used for accurate object tracking. In cases when the tracker encounters ambiguous appearance information, the motion features could provide complementary and discriminative information to improve tracking performances. Experimental results on various satellite videos show that the proposed method achieves better tracking performance than other state-of-the-arts.

16.  Small Target Tracking in Satellite Videos Using Background Compensation  
  [[Paper]](https://ieeexplore.ieee.org/document/9044613)  No code  
  **Publications**: IEEE Transactions on Geoscience and Remote Sensing, 2020  
  **Abstract**: Through the use of video technology, satellites can detect dynamic targets and analyze their motion characteristics. Target tracking can extract dynamic information about key ground targets for target monitoring and trajectory prediction by satellite video. Tracking algorithms are affected by target motion characteristics, such as velocity and direction, as well as background characteristics, such as illumination changes, occlusion, and background similarities with the target. However, these problems are seldom studied with satellite video cameras. Current algorithms are unsuitable for satellite video because of the poor texture and color features of the target in satellite video. Therefore, in this article, we enhance target tracking for satellite video technology using two aspects: 1) sample training strategy and 2) sample characterization. We establish a filter training mechanism for the target and background to improve the discrimination ability of the tracking algorithm. We then build a target feature model using a Gabor filter to enhance the contrast between the target and background. Moreover, we propose a tracking state evaluation index to avoid tracking drift. Tracking experiments using nine sets of Jilin-1 satellite videos show that the proposed approach can accurately locate a target under weak feature attributes. Therefore, this article contributes to more robust tracking using satellite video technology.
  
17.  Object Tracking on Satellite Videos: A Correlation Filter-Based Tracking Method With Trajectory Correction by Kalman Filter  
  [[Paper]](https://ieeexplore.ieee.org/document/8809377)  No code  
  **Publications**: IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 2019  
  **Abstract**: Object tracking toward satellite videos faces various challenges, such as small size of the moving object, few texture, background similarities, etc. In this article, we propose a high-speed correlation filter (CF)-based tracker for object tracking on satellite videos. It takes advantage of the global motion characteristics of the moving target in satellite videos to constrain the tracking process, which is achieved by applying a Kalman filter (KF) to correct the tracking trajectory of the moving target. Thus, our tracker is named CFKF. Besides, a tracking confidence module is designed to pass information from the CF-based position detector to the KF-based trajectory corrector, and a constant optimized model update frequency is studied to speed up the tracker, as well as improve its performance. Furthermore, the target's orientation during the tracking process can be obtained by utilizing an orientation detector based on slope calculation. Experiments conducted on the satellite video datasets demonstrate that our tracker CFKF outperforms the other representative CF-based tracking methods in terms of accuracy and robustness and is also fast in speed.

18.  Object Tracking in Satellite Videos by Improved Correlation Filters With Motion Estimations  
  [[Paper]](https://ieeexplore.ieee.org/document/8880656)  No code  
  **Publications**: IEEE Transactions on Geoscience and Remote Sensing, 2019  
  **Abstract**: As a new method of Earth observation, video satellite is capable of monitoring specific events on the Earth's surface continuously by providing high-temporal resolution remote sensing images. The video observations enable a variety of new satellite applications such as object tracking and road traffic monitoring. In this article, we address the problem of fast object tracking in satellite videos, by developing a novel tracking algorithm based on correlation filters embedded with motion estimations. Based on the kernelized correlation filter (KCF), the proposed algorithm provides the following improvements: 1) proposing a novel motion estimation (ME) algorithm by combining the Kalman filter and motion trajectory averaging and mitigating the boundary effects of KCF by using this ME algorithm and 2) solving the problem of tracking failure when a moving object is partially or completely occluded. The experimental results demonstrate that our algorithm can track the moving object in satellite videos with 95% accuracy.
  
19.  Tracking Objects From Satellite Videos: A Velocity Feature Based Correlation Filter  
  [[Paper]](https://ieeexplore.ieee.org/document/8736008)  No code  
  **Publications**: IEEE Transactions on Geoscience and Remote Sensing, 2019  
  **Abstract**: Satellite video target tracking is a new topic in the remote sensing field, which refers to tracking moving objects of interest from satellite video in real time. The target of interest usually occupies only a few pixels in a satellite video image, even when the train is long. Thus, satellite video target tracking still faces new challenges compared with traditional visual tracking, including the detection of low-resolution targets, features with less representation, and targets with an extremely similar background. Little research has been done on satellite video target tracking, and little is known about whether or not the existing tracking algorithms can still work on the satellite video data. This paper, for the first time, intensively investigated 13 typical trackers in traditional visual tracking. The experimental results suggest that most of the state-of-the-art tracking algorithms mainly rely on luminance, color features, or convolutional features, and they fail to track satellite video targets due to their inadequate representation features. To overcome this difficulty, we propose a velocity correlation filter (VCF) algorithm, which employs both a velocity feature and an inertia mechanism (IM) to construct a specific kernel correlation filter for the satellite video target tracking. The velocity feature has a high discriminative ability to detect moving targets in satellite videos, and the IM can prevent model drift adaptively. Experimental results on three real satellite video data sets show that the VCF outperforms state-of-the-art tracking methods with regard to precision and success plots while running at over 100 frames per second.
  
20.  Can We Track Targets From Space? A Hybrid Kernel Correlation Filter Tracker for Satellite Video  
  [[Paper]](https://ieeexplore.ieee.org/document/8789388)  No code  
  **Publications**: IEEE Transactions on Geoscience and Remote Sensing, 2019  
  **Abstract**: Despite the great success of correlation filter-based trackers in visual tracking, it is questionable whether they can still perform on the satellite video data, acquired by a satellite or space station very high above the earth. The difficulty lies in that the targets usually occupy only a few pixels compared with the image size of over one million pixels and almost melt into the similar background. Since correlation filter models strongly depend on the quality of features and the spatial layout of the tracked object, they would probably fail on satellite video tracking tasks. In this paper, we propose a hybrid kernel correlation filter (HKCF) tracker employing two complementary features adaptively in a ridge regression framework. One feature is the optical flow that can detect variation pixels of the target. The other one is the histogram of oriented gradient that can capture the contour and texture information in the target, and an adaptive fusion strategy is proposed to employ the strengths of both features in different satellite videos. Quantitative evaluations are performed on six real satellite video data sets. The results show that our approach outperforms state-of-the-art tracking methods while running at more than 100 frames/s.
  
21.  Object Tracking in Satellite Videos Based on a Multiframe Optical Flow Tracker  
  [[Paper]](https://ieeexplore.ieee.org/document/8735957)  No code  
  **Publications**: IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 2019  
  **Abstract**: Object tracking is a hot topic in computer vision. Thanks to the booming of the very high resolution (VHR) remote sensing techniques, it is now possible to track targets of interests in satellite videos. However, since the targets in the satellite videos are usually too small in comparison with the entire image, and too similar with the background, most state-of-the-art algorithms failed to track the target in satellite videos with a satisfactory accuracy. Due to the fact that optical flow shows great potential to detect even the slight movement of the targets, we proposed a multiframe optical flow tracker for object tracking in satellite videos. The Lucas-Kanade optical flow method was fused with the HSV color system and integral image to track the targets in the satellite videos, while multiframe difference method was utilized in the optical flow tracker for a better interpretation. The experiments with five VHR remote sensing satellite video datasets indicate that compared with state-of-the-art object tracking algorithms, the proposed method can track the target more accurately.
  
22.  Object Tracking in Satellite Videos by Fusing the Kernel Correlation Filter and the Three-Frame-Difference Algorithm  
  [[Paper]](https://ieeexplore.ieee.org/document/8225723)  No code  
  **Publications**: IEEE Geoscience and Remote Sensing Letters, 2017  
  **Abstract**: Object tracking is a popular topic in the field of computer vision. The detailed spatial information provided by a very high resolution remote sensing sensor makes it possible to track targets of interest in satellite videos. In recent years, correlation filters have yielded promising results. However, in terms of dealing with object tracking in satellite videos, the kernel correlation filter (KCF) tracker achieves poor results due to the fact that the size of each target is too small compared with the entire image, and the target and the background are very similar. Therefore, in this letter, we propose a new object tracking method for satellite videos by fusing the KCF tracker and a three-frame-difference algorithm. A specific strategy is proposed herein for taking advantage of the KCF tracker and the three-frame-difference algorithm to build a strong tracker. We evaluate the proposed method in three satellite videos and show its superiority to other state-of-the-art tracking methods.


### MOT
### 运动目标检测
